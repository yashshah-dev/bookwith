####################################################
# General Settings
####################################################
PORT=8000

####################################################
# LLM
####################################################
OPENAI_API_KEY=xxx
GEMINI_API_KEY=xxx

####################################################
# AI Provider Configuration
####################################################
# Choose embedding provider: "openai", "huggingface", or "ollama"
EMBEDDING_PROVIDER=ollama

# Choose LLM provider: "openai", "huggingface", or "ollama"
LLM_PROVIDER=ollama

####################################################
# Ollama Configuration (Local, Recommended for Development)
####################################################
# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Ollama chat model - Install with: ollama pull <model>
# Popular models:
# - llama3.2 (default, 3B params, fast, good quality)
# - llama3.1 (8B params, better quality)
# - mistral (7B params, excellent for chat)
# - phi3 (3.8B params, fast)
# - gemma2 (9B params, Google model)
# - qwen2.5 (various sizes, multilingual)
OLLAMA_MODEL=llama3.2

# Ollama embedding model - Install with: ollama pull nomic-embed-text
# - nomic-embed-text (default, 137M params, good quality)
# - mxbai-embed-large (335M params, higher quality)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

####################################################
# Hugging Face Settings
####################################################
# Optional: HuggingFace API token for private models or higher rate limits
# Get your token at: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=xxx

# Embedding model for vector search (using sentence-transformers)
# Popular models:
# - sentence-transformers/all-MiniLM-L6-v2 (default, lightweight, good performance)
# - sentence-transformers/all-mpnet-base-v2 (higher quality, slower)
# - BAAI/bge-small-en-v1.5 (good for English)
HUGGINGFACE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Chat completion model (using Inference API)
# Free tier models (confirmed working):
# - gpt2 (default, always available, good for general text)
# - distilgpt2 (smaller, faster version of GPT-2)
# - EleutherAI/gpt-neo-125m (newer architecture, small model)
HUGGINGFACE_LLM_MODEL=gpt2

####################################################
# Storage
####################################################
# For develop features related to synchronization,
# you should register an app on Dropbox:
# https://www.dropbox.com/developers/apps/create
# DROPBOX_CLIENT_ID=xxx
# DROPBOX_CLIENT_SECRET=xxx

####################################################
# LangChain
####################################################
LANGSMITH_TRACING=true
LANGCHAIN_API_KEY=xxx
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_PROJECT=bookwith

####################################################
# Supabase
####################################################
DATABASE_URL=postgresql://postgres:postgres@127.0.0.1:54322/postgres

# API_URL=http://127.0.0.1:54321
# GRAPHQL_URL=http://127.0.0.1:54321/graphql/v1
# S3_STORAGE_URL=http://127.0.0.1:54321/storage/v1/s3
# STUDIO_URL=http://127.0.0.1:54323
# INBUCKET_URL=http://127.0.0.1:54324
# JWT_SECRET=xxx
# ANON_KEY=xxx
# SERVICE_ROLE_KEY=xxx
# S3_ACCESS_KEY=xxx
# S3_SECRET_KEY=xxx
# S3_REGION=local

####################################################
# Googl Cloud
####################################################
GCS_EMULATOR_HOST=http://localhost:4443
GCP_PROJECT_ID=bookwith
GCS_BUCKET_NAME=bookwith-bucket
